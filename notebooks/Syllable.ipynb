{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Syllable",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMcMe7FyhWvTno7ka9GiHq0"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CaKQj5AVhKR_"
      },
      "source": [
        "Syllable - Joseph Jojoe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pUgwfh0oKjss",
        "outputId": "f8380364-f87e-41ef-fa23-56b2c3ff6f0f"
      },
      "source": [
        "!pip install tensorflow_addons"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow_addons\n",
            "  Downloading tensorflow_addons-0.15.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 3.1 MB/s eta 0:00:01\r\u001b[K     |▋                               | 20 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |▉                               | 30 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 40 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 51 kB 5.8 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 61 kB 6.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 71 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 81 kB 6.8 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 92 kB 6.9 MB/s eta 0:00:01\r\u001b[K     |███                             | 102 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 112 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 122 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 133 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 143 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 153 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 163 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████                           | 174 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 184 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 194 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 204 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 215 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 225 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 235 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████                         | 245 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 256 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 266 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████                        | 276 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 286 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 296 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████▉                       | 307 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 317 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 327 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 337 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 348 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 358 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 368 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 378 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 389 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 399 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 409 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 419 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 430 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 440 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 450 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 460 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 471 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 481 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 491 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 501 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 512 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 522 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 532 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 542 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 552 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 563 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 573 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 583 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 593 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 604 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 614 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 624 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 634 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 645 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 655 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 665 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 675 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 686 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 696 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 706 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 716 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 727 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 737 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 747 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 757 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 768 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 778 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 788 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 798 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 808 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 819 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 829 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 839 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 849 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 860 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 870 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 880 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 890 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 901 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 911 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 921 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 931 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 942 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 952 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 962 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 972 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 983 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 993 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.0 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.0 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.0 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.0 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.0 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 1.1 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.1 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 1.1 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.1 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.1 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.1 MB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.1 MB 7.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n",
            "Installing collected packages: tensorflow-addons\n",
            "Successfully installed tensorflow-addons-0.15.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csu57YRLhUPe"
      },
      "source": [
        "# Imports dependencies\n",
        "from google.colab import files\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import tensorflow_addons as tfa\n",
        "from tensorflow.keras import regularizers\n",
        "from keras.models import Model\n",
        "import pathlib\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import string\n",
        "import random\n",
        "from keras.preprocessing.text import Tokenizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "jpAxHCsohese",
        "outputId": "7f135ff3-d0c6-4f3e-8a68-2654a7b9a981"
      },
      "source": [
        "uploaded = files.upload()\n",
        "# Upload dataset"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-f2f58a8d-63de-4506-a1bf-c8c6723d0083\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-f2f58a8d-63de-4506-a1bf-c8c6723d0083\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving preprocessed.txt to preprocessed.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vjbfSUbohytB"
      },
      "source": [
        "# Loads in syllable data\n",
        "dataframe = pd.read_csv(\"preprocessed.txt\",\n",
        "                        sep=\",\",\n",
        "                        encoding=\"ISO-8859-1\",\n",
        "                        names=[\"word\", \"label\"])\n",
        "# Necessary to specify str type for pandas columns\n",
        "dataframe = dataframe.astype(str)\n",
        "words = dataframe['word'].tolist()\n",
        "labels = dataframe['label'].tolist()\n",
        "# Converts each label to numpy array\n",
        "for i in range(0, len(labels)):\n",
        "    labels[i] = list(labels[i])\n",
        "    for j in range(0, len(labels[i])):\n",
        "        labels[i][j] = int(labels[i][j])\n",
        "for i in range(0, len(labels)):\n",
        "    labels[i] = np.array(labels[i])"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gDS7CtLiAIj"
      },
      "source": [
        "# Vectorises syllable strings by treating each character as a token\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(words)\n",
        "words = tokenizer.texts_to_sequences(words)\n",
        "for i in range(0, len(words)):\n",
        "    words[i] = np.array(words[i], dtype=float)\n",
        "\n",
        "padded_inputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    words, padding=\"post\", maxlen=15\n",
        ")\n",
        "padded_outputs = tf.keras.preprocessing.sequence.pad_sequences(\n",
        "    labels, padding=\"post\", maxlen=15\n",
        ")\n",
        "\n",
        "# Normalisation\n",
        "maximum_token = 64\n",
        "for element in range(0, len(words)):\n",
        "    words[element] = words[element] / maximum_token"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgZKQGe1iFpj"
      },
      "source": [
        "# shuffles data\n",
        "seed = random.random()\n",
        "random.seed(seed)\n",
        "random.shuffle(padded_inputs)\n",
        "random.seed(seed)\n",
        "random.shuffle(padded_outputs)\n",
        "\n",
        "# splits into training and validation sets (80-20 split)\n",
        "validation_inputs = padded_inputs[-35497:]\n",
        "validation_outputs = padded_outputs[-35497:]\n",
        "padded_inputs = padded_inputs[:-35497]\n",
        "padded_outputs = padded_outputs[:-35497]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQezB-7cRHOC"
      },
      "source": [
        "# Custom loss function - mean of binary crossentropy and mean squared error\n",
        "def mean_weighted_bce_mse(y_true, y_prediction):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_prediction = tf.cast(y_prediction, tf.float32)\n",
        "\n",
        "    # Binary crossentropy with weighting\n",
        "    epsilon = 1e-6\n",
        "    positive_weight = 4.108897148948174\n",
        "    loss_positive = y_true * tf.math.log(y_prediction + epsilon)\n",
        "    loss_negative = (1 - y_true) * tf.math.log(1 - y_prediction + epsilon)\n",
        "    bce_loss = tf.math.reduce_mean(tf.math.negative(positive_weight * loss_positive + loss_negative))\n",
        "    \n",
        "    # Mean squared error\n",
        "    mse = tf.keras.losses.MeanSquaredError()\n",
        "    mse_loss = mse(y_true, y_prediction)\n",
        "\n",
        "    averaged_bce_mse = (bce_loss + mse_loss) / 2\n",
        "    return averaged_bce_mse"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Df2UpqpKl16x"
      },
      "source": [
        "def inception_module(inputs):\n",
        "    inception_branch_1 = tf.keras.layers.Conv1D(128, kernel_size=1, strides=2, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n",
        "    inception_branch_1 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_1.shape[1]))(inception_branch_1)\n",
        "\n",
        "    inception_branch_2 = tf.keras.layers.Conv1D(128, kernel_size=1, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n",
        "    inception_branch_2 = tf.keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_2)\n",
        "    inception_branch_2 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_2.shape[1]))(inception_branch_2)\n",
        "\n",
        "    inception_branch_3 = tf.keras.layers.AveragePooling1D(pool_size=3, strides=2)(inputs)\n",
        "    inception_branch_3 = tf.keras.layers.Conv1D(128, kernel_size=3, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_3)\n",
        "    inception_branch_3 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_3.shape[1]))(inception_branch_3)\n",
        "\n",
        "    inception_branch_4 = tf.keras.layers.Conv1D(128, kernel_size=1, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inputs)\n",
        "    inception_branch_4 = tf.keras.layers.Conv1D(128, kernel_size=3, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_4)\n",
        "    inception_branch_4 = tf.keras.layers.Conv1D(128, kernel_size=3, strides=2, activation=\"tanh\", activity_regularizer=tf.keras.regularizers.l2(1e-5))(inception_branch_4)\n",
        "    inception_branch_4 = tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_branch_4.shape[1]))(inception_branch_4)\n",
        "\n",
        "    inception_output = tf.keras.layers.concatenate([inception_branch_1, inception_branch_2, inception_branch_3, inception_branch_4, inputs])\n",
        "    return inception_output"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOip602ziQok"
      },
      "source": [
        "inputs = tf.keras.Input(shape=(15,))\n",
        "embedded_inputs = tf.keras.layers.Embedding(64, 256, mask_zero=True)(inputs)\n",
        "embedded_inputs = tf.keras.layers.Dropout(0.25)(embedded_inputs)\n",
        "\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True, dropout=0.1, activity_regularizer=tf.keras.regularizers.l2(1e-5)))(embedded_inputs)\n",
        "x = tf.keras.layers.concatenate([x, embedded_inputs])\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True, dropout=0.1, activity_regularizer=tf.keras.regularizers.l2(1e-5)))(x)\n",
        "x = tf.keras.layers.concatenate([x, embedded_inputs])\n",
        "x = tf.keras.layers.Bidirectional(tf.keras.layers.GRU(256, return_sequences=True, activity_regularizer=tf.keras.regularizers.l2(1e-5)))(x)\n",
        "\n",
        "inception_output = inception_module(embedded_inputs)\n",
        "inception_output = tf.keras.layers.MaxPooling1D()(inception_output)\n",
        "inception_output =  tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_output.shape[1]))(inception_output)\n",
        "inception_output = tf.keras.layers.Dropout(0.5)(inception_output)\n",
        "inception_output = inception_module(inception_output)\n",
        "inception_output = tf.keras.layers.MaxPooling1D()(inception_output)\n",
        "inception_output =  tf.keras.layers.ZeroPadding1D(padding=(0, 15 - inception_output.shape[1]))(inception_output)\n",
        "\n",
        "output = tf.keras.layers.concatenate([x, inception_output, embedded_inputs])\n",
        "output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation=\"relu\"))(output)\n",
        "output = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(64, activation=\"relu\"))(output)\n",
        "output = tf.keras.layers.GlobalMaxPool1D()(output)\n",
        "output = tf.keras.layers.Dense(15, activation=\"sigmoid\")(output)\n",
        "\n",
        "metrics = [\"binary_accuracy\",\n",
        "           tfa.metrics.F1Score(num_classes=15, threshold=0.5),\n",
        "           tfa.metrics.HammingLoss(mode='multilabel', threshold=0.5),\n",
        "           tf.keras.metrics.Recall(),\n",
        "           tf.keras.metrics.Precision(),\n",
        "           tf.keras.metrics.AUC(multi_label=True, num_labels=15)]\n",
        "\n",
        "model = tf.keras.models.Model(inputs=inputs, outputs=output)\n",
        "model.compile(optimizer=\"adam\",\n",
        "              loss=mean_weighted_bce_mse,\n",
        "              metrics=metrics,\n",
        "              steps_per_execution=128)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rM_seEmJg7ux"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_CQt-B_ibtm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "cc8d6be3-21a3-4f1b-9dba-70309bd4f3c8"
      },
      "source": [
        "history = model.fit(padded_inputs,\n",
        "                    padded_outputs,\n",
        "                    validation_data=(validation_inputs, validation_outputs),\n",
        "                    epochs=200,\n",
        "                    batch_size=512)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "278/278 [==============================] - 92s 330ms/step - loss: 0.2271 - binary_accuracy: 0.8858 - f1_score: 0.5355 - hamming_loss: 0.1142 - recall: 0.8641 - precision: 0.5425 - auc: 0.8674 - val_loss: 0.1846 - val_binary_accuracy: 0.9122 - val_f1_score: 0.6572 - val_hamming_loss: 0.0878 - val_recall: 0.9260 - val_precision: 0.6428 - val_auc: 0.9014\n",
            "Epoch 2/200\n",
            "278/278 [==============================] - 26s 95ms/step - loss: 0.1475 - binary_accuracy: 0.9360 - f1_score: 0.7001 - hamming_loss: 0.0640 - recall: 0.9189 - precision: 0.6949 - auc: 0.9086 - val_loss: 0.1429 - val_binary_accuracy: 0.9378 - val_f1_score: 0.7419 - val_hamming_loss: 0.0622 - val_recall: 0.9396 - val_precision: 0.7251 - val_auc: 0.9129\n",
            "Epoch 3/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.1186 - binary_accuracy: 0.9518 - f1_score: 0.7549 - hamming_loss: 0.0482 - recall: 0.9366 - precision: 0.7564 - auc: 0.9184 - val_loss: 0.1180 - val_binary_accuracy: 0.9538 - val_f1_score: 0.7719 - val_hamming_loss: 0.0462 - val_recall: 0.9450 - val_precision: 0.7878 - val_auc: 0.9192\n",
            "Epoch 4/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0953 - binary_accuracy: 0.9635 - f1_score: 0.7951 - hamming_loss: 0.0365 - recall: 0.9506 - precision: 0.8075 - auc: 0.9227 - val_loss: 0.1031 - val_binary_accuracy: 0.9614 - val_f1_score: 0.7975 - val_hamming_loss: 0.0386 - val_recall: 0.9535 - val_precision: 0.8181 - val_auc: 0.9225\n",
            "Epoch 5/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0768 - binary_accuracy: 0.9725 - f1_score: 0.8287 - hamming_loss: 0.0275 - recall: 0.9625 - precision: 0.8493 - auc: 0.9274 - val_loss: 0.0931 - val_binary_accuracy: 0.9681 - val_f1_score: 0.8312 - val_hamming_loss: 0.0319 - val_recall: 0.9570 - val_precision: 0.8487 - val_auc: 0.9232\n",
            "Epoch 6/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0615 - binary_accuracy: 0.9794 - f1_score: 0.8484 - hamming_loss: 0.0206 - recall: 0.9715 - precision: 0.8838 - auc: 0.9296 - val_loss: 0.0838 - val_binary_accuracy: 0.9727 - val_f1_score: 0.8270 - val_hamming_loss: 0.0273 - val_recall: 0.9632 - val_precision: 0.8684 - val_auc: 0.9257\n",
            "Epoch 7/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0501 - binary_accuracy: 0.9842 - f1_score: 0.8662 - hamming_loss: 0.0158 - recall: 0.9782 - precision: 0.9094 - auc: 0.9309 - val_loss: 0.0830 - val_binary_accuracy: 0.9753 - val_f1_score: 0.8446 - val_hamming_loss: 0.0247 - val_recall: 0.9608 - val_precision: 0.8838 - val_auc: 0.9258\n",
            "Epoch 8/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0420 - binary_accuracy: 0.9877 - f1_score: 0.8840 - hamming_loss: 0.0123 - recall: 0.9830 - precision: 0.9282 - auc: 0.9317 - val_loss: 0.0856 - val_binary_accuracy: 0.9778 - val_f1_score: 0.8551 - val_hamming_loss: 0.0222 - val_recall: 0.9550 - val_precision: 0.9019 - val_auc: 0.9255\n",
            "Epoch 9/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0361 - binary_accuracy: 0.9899 - f1_score: 0.8920 - hamming_loss: 0.0101 - recall: 0.9860 - precision: 0.9403 - auc: 0.9321 - val_loss: 0.0843 - val_binary_accuracy: 0.9800 - val_f1_score: 0.8579 - val_hamming_loss: 0.0200 - val_recall: 0.9574 - val_precision: 0.9128 - val_auc: 0.9244\n",
            "Epoch 10/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0312 - binary_accuracy: 0.9919 - f1_score: 0.8992 - hamming_loss: 0.0081 - recall: 0.9888 - precision: 0.9515 - auc: 0.9324 - val_loss: 0.0823 - val_binary_accuracy: 0.9802 - val_f1_score: 0.8428 - val_hamming_loss: 0.0198 - val_recall: 0.9615 - val_precision: 0.9106 - val_auc: 0.9244\n",
            "Epoch 11/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0280 - binary_accuracy: 0.9930 - f1_score: 0.9006 - hamming_loss: 0.0070 - recall: 0.9906 - precision: 0.9580 - auc: 0.9325 - val_loss: 0.0828 - val_binary_accuracy: 0.9812 - val_f1_score: 0.8580 - val_hamming_loss: 0.0188 - val_recall: 0.9600 - val_precision: 0.9176 - val_auc: 0.9252\n",
            "Epoch 12/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0250 - binary_accuracy: 0.9940 - f1_score: 0.9097 - hamming_loss: 0.0060 - recall: 0.9919 - precision: 0.9634 - auc: 0.9327 - val_loss: 0.0855 - val_binary_accuracy: 0.9810 - val_f1_score: 0.8484 - val_hamming_loss: 0.0190 - val_recall: 0.9597 - val_precision: 0.9170 - val_auc: 0.9228\n",
            "Epoch 13/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0242 - binary_accuracy: 0.9943 - f1_score: 0.9105 - hamming_loss: 0.0057 - recall: 0.9923 - precision: 0.9655 - auc: 0.9327 - val_loss: 0.0862 - val_binary_accuracy: 0.9816 - val_f1_score: 0.8511 - val_hamming_loss: 0.0184 - val_recall: 0.9608 - val_precision: 0.9194 - val_auc: 0.9240\n",
            "Epoch 14/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0222 - binary_accuracy: 0.9949 - f1_score: 0.9109 - hamming_loss: 0.0051 - recall: 0.9931 - precision: 0.9690 - auc: 0.9328 - val_loss: 0.0887 - val_binary_accuracy: 0.9813 - val_f1_score: 0.8583 - val_hamming_loss: 0.0187 - val_recall: 0.9611 - val_precision: 0.9175 - val_auc: 0.9250\n",
            "Epoch 15/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0212 - binary_accuracy: 0.9952 - f1_score: 0.9105 - hamming_loss: 0.0048 - recall: 0.9935 - precision: 0.9710 - auc: 0.9328 - val_loss: 0.0890 - val_binary_accuracy: 0.9827 - val_f1_score: 0.8550 - val_hamming_loss: 0.0173 - val_recall: 0.9565 - val_precision: 0.9293 - val_auc: 0.9249\n",
            "Epoch 16/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0204 - binary_accuracy: 0.9955 - f1_score: 0.9127 - hamming_loss: 0.0045 - recall: 0.9939 - precision: 0.9728 - auc: 0.9328 - val_loss: 0.0873 - val_binary_accuracy: 0.9833 - val_f1_score: 0.8682 - val_hamming_loss: 0.0167 - val_recall: 0.9584 - val_precision: 0.9317 - val_auc: 0.9247\n",
            "Epoch 17/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0192 - binary_accuracy: 0.9958 - f1_score: 0.9152 - hamming_loss: 0.0042 - recall: 0.9945 - precision: 0.9743 - auc: 0.9329 - val_loss: 0.0909 - val_binary_accuracy: 0.9831 - val_f1_score: 0.8703 - val_hamming_loss: 0.0169 - val_recall: 0.9575 - val_precision: 0.9310 - val_auc: 0.9245\n",
            "Epoch 18/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0189 - binary_accuracy: 0.9959 - f1_score: 0.9148 - hamming_loss: 0.0041 - recall: 0.9944 - precision: 0.9749 - auc: 0.9329 - val_loss: 0.0899 - val_binary_accuracy: 0.9830 - val_f1_score: 0.8663 - val_hamming_loss: 0.0170 - val_recall: 0.9577 - val_precision: 0.9307 - val_auc: 0.9222\n",
            "Epoch 19/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0187 - binary_accuracy: 0.9959 - f1_score: 0.9120 - hamming_loss: 0.0041 - recall: 0.9946 - precision: 0.9750 - auc: 0.9329 - val_loss: 0.0887 - val_binary_accuracy: 0.9824 - val_f1_score: 0.8641 - val_hamming_loss: 0.0176 - val_recall: 0.9604 - val_precision: 0.9246 - val_auc: 0.9232\n",
            "Epoch 20/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0178 - binary_accuracy: 0.9962 - f1_score: 0.9184 - hamming_loss: 0.0038 - recall: 0.9949 - precision: 0.9766 - auc: 0.9329 - val_loss: 0.0879 - val_binary_accuracy: 0.9837 - val_f1_score: 0.8757 - val_hamming_loss: 0.0163 - val_recall: 0.9586 - val_precision: 0.9341 - val_auc: 0.9244\n",
            "Epoch 21/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0173 - binary_accuracy: 0.9962 - f1_score: 0.9192 - hamming_loss: 0.0038 - recall: 0.9950 - precision: 0.9769 - auc: 0.9329 - val_loss: 0.0930 - val_binary_accuracy: 0.9828 - val_f1_score: 0.8598 - val_hamming_loss: 0.0172 - val_recall: 0.9585 - val_precision: 0.9284 - val_auc: 0.9204\n",
            "Epoch 22/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0169 - binary_accuracy: 0.9964 - f1_score: 0.9184 - hamming_loss: 0.0036 - recall: 0.9950 - precision: 0.9779 - auc: 0.9329 - val_loss: 0.0898 - val_binary_accuracy: 0.9833 - val_f1_score: 0.8674 - val_hamming_loss: 0.0167 - val_recall: 0.9570 - val_precision: 0.9329 - val_auc: 0.9229\n",
            "Epoch 23/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0165 - binary_accuracy: 0.9964 - f1_score: 0.9216 - hamming_loss: 0.0036 - recall: 0.9952 - precision: 0.9782 - auc: 0.9330 - val_loss: 0.0914 - val_binary_accuracy: 0.9836 - val_f1_score: 0.8646 - val_hamming_loss: 0.0164 - val_recall: 0.9581 - val_precision: 0.9337 - val_auc: 0.9216\n",
            "Epoch 24/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0167 - binary_accuracy: 0.9964 - f1_score: 0.9172 - hamming_loss: 0.0036 - recall: 0.9951 - precision: 0.9778 - auc: 0.9329 - val_loss: 0.0906 - val_binary_accuracy: 0.9839 - val_f1_score: 0.8741 - val_hamming_loss: 0.0161 - val_recall: 0.9585 - val_precision: 0.9353 - val_auc: 0.9228\n",
            "Epoch 25/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0161 - binary_accuracy: 0.9965 - f1_score: 0.9194 - hamming_loss: 0.0035 - recall: 0.9952 - precision: 0.9787 - auc: 0.9329 - val_loss: 0.0936 - val_binary_accuracy: 0.9834 - val_f1_score: 0.8677 - val_hamming_loss: 0.0166 - val_recall: 0.9592 - val_precision: 0.9315 - val_auc: 0.9227\n",
            "Epoch 26/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0163 - binary_accuracy: 0.9965 - f1_score: 0.9211 - hamming_loss: 0.0035 - recall: 0.9952 - precision: 0.9785 - auc: 0.9329 - val_loss: 0.0932 - val_binary_accuracy: 0.9840 - val_f1_score: 0.8706 - val_hamming_loss: 0.0160 - val_recall: 0.9584 - val_precision: 0.9358 - val_auc: 0.9215\n",
            "Epoch 27/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0152 - binary_accuracy: 0.9968 - f1_score: 0.9179 - hamming_loss: 0.0032 - recall: 0.9957 - precision: 0.9802 - auc: 0.9330 - val_loss: 0.0898 - val_binary_accuracy: 0.9846 - val_f1_score: 0.8756 - val_hamming_loss: 0.0154 - val_recall: 0.9587 - val_precision: 0.9390 - val_auc: 0.9217\n",
            "Epoch 28/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0142 - binary_accuracy: 0.9970 - f1_score: 0.9222 - hamming_loss: 0.0030 - recall: 0.9961 - precision: 0.9813 - auc: 0.9330 - val_loss: 0.0897 - val_binary_accuracy: 0.9838 - val_f1_score: 0.8610 - val_hamming_loss: 0.0162 - val_recall: 0.9604 - val_precision: 0.9331 - val_auc: 0.9240\n",
            "Epoch 29/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0146 - binary_accuracy: 0.9968 - f1_score: 0.9200 - hamming_loss: 0.0032 - recall: 0.9958 - precision: 0.9807 - auc: 0.9330 - val_loss: 0.0944 - val_binary_accuracy: 0.9838 - val_f1_score: 0.8604 - val_hamming_loss: 0.0162 - val_recall: 0.9578 - val_precision: 0.9353 - val_auc: 0.9202\n",
            "Epoch 30/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0144 - binary_accuracy: 0.9968 - f1_score: 0.9215 - hamming_loss: 0.0032 - recall: 0.9958 - precision: 0.9806 - auc: 0.9330 - val_loss: 0.0894 - val_binary_accuracy: 0.9841 - val_f1_score: 0.8642 - val_hamming_loss: 0.0159 - val_recall: 0.9591 - val_precision: 0.9362 - val_auc: 0.9241\n",
            "Epoch 31/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0137 - binary_accuracy: 0.9970 - f1_score: 0.9234 - hamming_loss: 0.0030 - recall: 0.9962 - precision: 0.9817 - auc: 0.9330 - val_loss: 0.0911 - val_binary_accuracy: 0.9842 - val_f1_score: 0.8707 - val_hamming_loss: 0.0158 - val_recall: 0.9584 - val_precision: 0.9373 - val_auc: 0.9229\n",
            "Epoch 32/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0140 - binary_accuracy: 0.9970 - f1_score: 0.9220 - hamming_loss: 0.0030 - recall: 0.9960 - precision: 0.9813 - auc: 0.9330 - val_loss: 0.0898 - val_binary_accuracy: 0.9841 - val_f1_score: 0.8640 - val_hamming_loss: 0.0159 - val_recall: 0.9621 - val_precision: 0.9336 - val_auc: 0.9214\n",
            "Epoch 33/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0136 - binary_accuracy: 0.9970 - f1_score: 0.9210 - hamming_loss: 0.0030 - recall: 0.9960 - precision: 0.9815 - auc: 0.9330 - val_loss: 0.0928 - val_binary_accuracy: 0.9841 - val_f1_score: 0.8792 - val_hamming_loss: 0.0159 - val_recall: 0.9588 - val_precision: 0.9363 - val_auc: 0.9227\n",
            "Epoch 34/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0139 - binary_accuracy: 0.9969 - f1_score: 0.9219 - hamming_loss: 0.0031 - recall: 0.9959 - precision: 0.9811 - auc: 0.9330 - val_loss: 0.0936 - val_binary_accuracy: 0.9838 - val_f1_score: 0.8607 - val_hamming_loss: 0.0162 - val_recall: 0.9594 - val_precision: 0.9341 - val_auc: 0.9237\n",
            "Epoch 35/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0143 - binary_accuracy: 0.9968 - f1_score: 0.9194 - hamming_loss: 0.0032 - recall: 0.9957 - precision: 0.9806 - auc: 0.9330 - val_loss: 0.0957 - val_binary_accuracy: 0.9831 - val_f1_score: 0.8367 - val_hamming_loss: 0.0169 - val_recall: 0.9589 - val_precision: 0.9298 - val_auc: 0.9236\n",
            "Epoch 36/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0130 - binary_accuracy: 0.9972 - f1_score: 0.9207 - hamming_loss: 0.0028 - recall: 0.9964 - precision: 0.9825 - auc: 0.9331 - val_loss: 0.0946 - val_binary_accuracy: 0.9847 - val_f1_score: 0.8688 - val_hamming_loss: 0.0153 - val_recall: 0.9583 - val_precision: 0.9406 - val_auc: 0.9209\n",
            "Epoch 37/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0127 - binary_accuracy: 0.9972 - f1_score: 0.9227 - hamming_loss: 0.0028 - recall: 0.9964 - precision: 0.9823 - auc: 0.9331 - val_loss: 0.0932 - val_binary_accuracy: 0.9844 - val_f1_score: 0.8728 - val_hamming_loss: 0.0156 - val_recall: 0.9603 - val_precision: 0.9367 - val_auc: 0.9206\n",
            "Epoch 38/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0135 - binary_accuracy: 0.9970 - f1_score: 0.9214 - hamming_loss: 0.0030 - recall: 0.9961 - precision: 0.9813 - auc: 0.9330 - val_loss: 0.0975 - val_binary_accuracy: 0.9835 - val_f1_score: 0.8600 - val_hamming_loss: 0.0165 - val_recall: 0.9567 - val_precision: 0.9344 - val_auc: 0.9185\n",
            "Epoch 39/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0131 - binary_accuracy: 0.9971 - f1_score: 0.9221 - hamming_loss: 0.0029 - recall: 0.9963 - precision: 0.9821 - auc: 0.9325 - val_loss: 0.0932 - val_binary_accuracy: 0.9845 - val_f1_score: 0.8496 - val_hamming_loss: 0.0155 - val_recall: 0.9579 - val_precision: 0.9392 - val_auc: 0.9239\n",
            "Epoch 40/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0126 - binary_accuracy: 0.9972 - f1_score: 0.9192 - hamming_loss: 0.0028 - recall: 0.9964 - precision: 0.9824 - auc: 0.9331 - val_loss: 0.0965 - val_binary_accuracy: 0.9840 - val_f1_score: 0.8619 - val_hamming_loss: 0.0160 - val_recall: 0.9579 - val_precision: 0.9360 - val_auc: 0.9160\n",
            "Epoch 41/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0134 - binary_accuracy: 0.9970 - f1_score: 0.9182 - hamming_loss: 0.0030 - recall: 0.9960 - precision: 0.9812 - auc: 0.9330 - val_loss: 0.0955 - val_binary_accuracy: 0.9843 - val_f1_score: 0.8672 - val_hamming_loss: 0.0157 - val_recall: 0.9587 - val_precision: 0.9377 - val_auc: 0.9219\n",
            "Epoch 42/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0126 - binary_accuracy: 0.9972 - f1_score: 0.9195 - hamming_loss: 0.0028 - recall: 0.9964 - precision: 0.9823 - auc: 0.9331 - val_loss: 0.0941 - val_binary_accuracy: 0.9844 - val_f1_score: 0.8577 - val_hamming_loss: 0.0156 - val_recall: 0.9596 - val_precision: 0.9375 - val_auc: 0.9093\n",
            "Epoch 43/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0117 - binary_accuracy: 0.9974 - f1_score: 0.9234 - hamming_loss: 0.0026 - recall: 0.9967 - precision: 0.9837 - auc: 0.9331 - val_loss: 0.0951 - val_binary_accuracy: 0.9848 - val_f1_score: 0.8746 - val_hamming_loss: 0.0152 - val_recall: 0.9578 - val_precision: 0.9416 - val_auc: 0.9221\n",
            "Epoch 44/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0122 - binary_accuracy: 0.9972 - f1_score: 0.9223 - hamming_loss: 0.0028 - recall: 0.9963 - precision: 0.9827 - auc: 0.9331 - val_loss: 0.0953 - val_binary_accuracy: 0.9844 - val_f1_score: 0.8760 - val_hamming_loss: 0.0156 - val_recall: 0.9578 - val_precision: 0.9389 - val_auc: 0.9221\n",
            "Epoch 45/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0121 - binary_accuracy: 0.9973 - f1_score: 0.9221 - hamming_loss: 0.0027 - recall: 0.9965 - precision: 0.9829 - auc: 0.9331 - val_loss: 0.0999 - val_binary_accuracy: 0.9851 - val_f1_score: 0.8811 - val_hamming_loss: 0.0149 - val_recall: 0.9565 - val_precision: 0.9444 - val_auc: 0.9206\n",
            "Epoch 46/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0112 - binary_accuracy: 0.9975 - f1_score: 0.9240 - hamming_loss: 0.0025 - recall: 0.9970 - precision: 0.9841 - auc: 0.9331 - val_loss: 0.0924 - val_binary_accuracy: 0.9850 - val_f1_score: 0.8739 - val_hamming_loss: 0.0150 - val_recall: 0.9599 - val_precision: 0.9408 - val_auc: 0.9211\n",
            "Epoch 47/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0121 - binary_accuracy: 0.9972 - f1_score: 0.9237 - hamming_loss: 0.0028 - recall: 0.9963 - precision: 0.9826 - auc: 0.9331 - val_loss: 0.1000 - val_binary_accuracy: 0.9842 - val_f1_score: 0.8761 - val_hamming_loss: 0.0158 - val_recall: 0.9562 - val_precision: 0.9390 - val_auc: 0.9201\n",
            "Epoch 48/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0124 - binary_accuracy: 0.9972 - f1_score: 0.9216 - hamming_loss: 0.0028 - recall: 0.9964 - precision: 0.9824 - auc: 0.9331 - val_loss: 0.0970 - val_binary_accuracy: 0.9845 - val_f1_score: 0.8666 - val_hamming_loss: 0.0155 - val_recall: 0.9589 - val_precision: 0.9385 - val_auc: 0.9172\n",
            "Epoch 49/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0115 - binary_accuracy: 0.9973 - f1_score: 0.9225 - hamming_loss: 0.0027 - recall: 0.9967 - precision: 0.9834 - auc: 0.9331 - val_loss: 0.0899 - val_binary_accuracy: 0.9853 - val_f1_score: 0.8755 - val_hamming_loss: 0.0147 - val_recall: 0.9609 - val_precision: 0.9417 - val_auc: 0.9223\n",
            "Epoch 50/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0112 - binary_accuracy: 0.9973 - f1_score: 0.9232 - hamming_loss: 0.0027 - recall: 0.9968 - precision: 0.9834 - auc: 0.9331 - val_loss: 0.0981 - val_binary_accuracy: 0.9853 - val_f1_score: 0.8645 - val_hamming_loss: 0.0147 - val_recall: 0.9566 - val_precision: 0.9452 - val_auc: 0.9228\n",
            "Epoch 51/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0106 - binary_accuracy: 0.9975 - f1_score: 0.9222 - hamming_loss: 0.0025 - recall: 0.9970 - precision: 0.9844 - auc: 0.9331 - val_loss: 0.0932 - val_binary_accuracy: 0.9855 - val_f1_score: 0.8787 - val_hamming_loss: 0.0145 - val_recall: 0.9588 - val_precision: 0.9450 - val_auc: 0.9235\n",
            "Epoch 52/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0109 - binary_accuracy: 0.9974 - f1_score: 0.9252 - hamming_loss: 0.0026 - recall: 0.9968 - precision: 0.9837 - auc: 0.9331 - val_loss: 0.0974 - val_binary_accuracy: 0.9846 - val_f1_score: 0.8684 - val_hamming_loss: 0.0154 - val_recall: 0.9590 - val_precision: 0.9393 - val_auc: 0.9212\n",
            "Epoch 53/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0115 - binary_accuracy: 0.9973 - f1_score: 0.9230 - hamming_loss: 0.0027 - recall: 0.9965 - precision: 0.9830 - auc: 0.9331 - val_loss: 0.0980 - val_binary_accuracy: 0.9843 - val_f1_score: 0.8661 - val_hamming_loss: 0.0157 - val_recall: 0.9594 - val_precision: 0.9368 - val_auc: 0.9204\n",
            "Epoch 54/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0118 - binary_accuracy: 0.9972 - f1_score: 0.9233 - hamming_loss: 0.0028 - recall: 0.9965 - precision: 0.9826 - auc: 0.9331 - val_loss: 0.1047 - val_binary_accuracy: 0.9843 - val_f1_score: 0.8672 - val_hamming_loss: 0.0157 - val_recall: 0.9559 - val_precision: 0.9400 - val_auc: 0.9214\n",
            "Epoch 55/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0119 - binary_accuracy: 0.9971 - f1_score: 0.9233 - hamming_loss: 0.0029 - recall: 0.9964 - precision: 0.9820 - auc: 0.9331 - val_loss: 0.0931 - val_binary_accuracy: 0.9851 - val_f1_score: 0.8762 - val_hamming_loss: 0.0149 - val_recall: 0.9601 - val_precision: 0.9412 - val_auc: 0.9221\n",
            "Epoch 56/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0116 - binary_accuracy: 0.9972 - f1_score: 0.9238 - hamming_loss: 0.0028 - recall: 0.9965 - precision: 0.9827 - auc: 0.9331 - val_loss: 0.0961 - val_binary_accuracy: 0.9850 - val_f1_score: 0.8686 - val_hamming_loss: 0.0150 - val_recall: 0.9580 - val_precision: 0.9423 - val_auc: 0.9230\n",
            "Epoch 57/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0116 - binary_accuracy: 0.9972 - f1_score: 0.9224 - hamming_loss: 0.0028 - recall: 0.9966 - precision: 0.9826 - auc: 0.9332 - val_loss: 0.0968 - val_binary_accuracy: 0.9852 - val_f1_score: 0.8674 - val_hamming_loss: 0.0148 - val_recall: 0.9599 - val_precision: 0.9417 - val_auc: 0.9219\n",
            "Epoch 58/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0109 - binary_accuracy: 0.9974 - f1_score: 0.9220 - hamming_loss: 0.0026 - recall: 0.9968 - precision: 0.9834 - auc: 0.9331 - val_loss: 0.0924 - val_binary_accuracy: 0.9854 - val_f1_score: 0.8836 - val_hamming_loss: 0.0146 - val_recall: 0.9619 - val_precision: 0.9413 - val_auc: 0.9233\n",
            "Epoch 59/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0112 - binary_accuracy: 0.9973 - f1_score: 0.9220 - hamming_loss: 0.0027 - recall: 0.9966 - precision: 0.9828 - auc: 0.9331 - val_loss: 0.0964 - val_binary_accuracy: 0.9847 - val_f1_score: 0.8684 - val_hamming_loss: 0.0153 - val_recall: 0.9590 - val_precision: 0.9397 - val_auc: 0.9191\n",
            "Epoch 60/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0104 - binary_accuracy: 0.9975 - f1_score: 0.9241 - hamming_loss: 0.0025 - recall: 0.9970 - precision: 0.9841 - auc: 0.9331 - val_loss: 0.1016 - val_binary_accuracy: 0.9851 - val_f1_score: 0.8695 - val_hamming_loss: 0.0149 - val_recall: 0.9573 - val_precision: 0.9433 - val_auc: 0.9180\n",
            "Epoch 61/200\n",
            "278/278 [==============================] - 26s 94ms/step - loss: 0.0097 - binary_accuracy: 0.9976 - f1_score: 0.9247 - hamming_loss: 0.0024 - recall: 0.9972 - precision: 0.9849 - auc: 0.9332 - val_loss: 0.0927 - val_binary_accuracy: 0.9852 - val_f1_score: 0.8735 - val_hamming_loss: 0.0148 - val_recall: 0.9611 - val_precision: 0.9412 - val_auc: 0.9234\n",
            "Epoch 62/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0094 - binary_accuracy: 0.9977 - f1_score: 0.9236 - hamming_loss: 0.0023 - recall: 0.9973 - precision: 0.9853 - auc: 0.9332 - val_loss: 0.0960 - val_binary_accuracy: 0.9855 - val_f1_score: 0.8699 - val_hamming_loss: 0.0145 - val_recall: 0.9610 - val_precision: 0.9431 - val_auc: 0.9228\n",
            "Epoch 63/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0094 - binary_accuracy: 0.9976 - f1_score: 0.9240 - hamming_loss: 0.0024 - recall: 0.9973 - precision: 0.9850 - auc: 0.9332 - val_loss: 0.0981 - val_binary_accuracy: 0.9853 - val_f1_score: 0.8732 - val_hamming_loss: 0.0147 - val_recall: 0.9588 - val_precision: 0.9433 - val_auc: 0.9194\n",
            "Epoch 64/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0100 - binary_accuracy: 0.9975 - f1_score: 0.9207 - hamming_loss: 0.0025 - recall: 0.9971 - precision: 0.9843 - auc: 0.9332 - val_loss: 0.0982 - val_binary_accuracy: 0.9847 - val_f1_score: 0.8627 - val_hamming_loss: 0.0153 - val_recall: 0.9589 - val_precision: 0.9400 - val_auc: 0.9216\n",
            "Epoch 65/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0104 - binary_accuracy: 0.9974 - f1_score: 0.9226 - hamming_loss: 0.0026 - recall: 0.9968 - precision: 0.9835 - auc: 0.9332 - val_loss: 0.1004 - val_binary_accuracy: 0.9847 - val_f1_score: 0.8613 - val_hamming_loss: 0.0153 - val_recall: 0.9597 - val_precision: 0.9390 - val_auc: 0.9212\n",
            "Epoch 66/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0107 - binary_accuracy: 0.9973 - f1_score: 0.9172 - hamming_loss: 0.0027 - recall: 0.9969 - precision: 0.9829 - auc: 0.9331 - val_loss: 0.1070 - val_binary_accuracy: 0.9843 - val_f1_score: 0.8658 - val_hamming_loss: 0.0157 - val_recall: 0.9571 - val_precision: 0.9391 - val_auc: 0.9143\n",
            "Epoch 67/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0128 - binary_accuracy: 0.9968 - f1_score: 0.9168 - hamming_loss: 0.0032 - recall: 0.9959 - precision: 0.9801 - auc: 0.9330 - val_loss: 0.0970 - val_binary_accuracy: 0.9847 - val_f1_score: 0.8770 - val_hamming_loss: 0.0153 - val_recall: 0.9621 - val_precision: 0.9372 - val_auc: 0.9206\n",
            "Epoch 68/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0107 - binary_accuracy: 0.9974 - f1_score: 0.9206 - hamming_loss: 0.0026 - recall: 0.9968 - precision: 0.9834 - auc: 0.9331 - val_loss: 0.0995 - val_binary_accuracy: 0.9853 - val_f1_score: 0.8744 - val_hamming_loss: 0.0147 - val_recall: 0.9619 - val_precision: 0.9412 - val_auc: 0.9167\n",
            "Epoch 69/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0095 - binary_accuracy: 0.9976 - f1_score: 0.9246 - hamming_loss: 0.0024 - recall: 0.9973 - precision: 0.9847 - auc: 0.9332 - val_loss: 0.0989 - val_binary_accuracy: 0.9844 - val_f1_score: 0.8711 - val_hamming_loss: 0.0156 - val_recall: 0.9605 - val_precision: 0.9369 - val_auc: 0.9169\n",
            "Epoch 70/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0099 - binary_accuracy: 0.9975 - f1_score: 0.9260 - hamming_loss: 0.0025 - recall: 0.9971 - precision: 0.9842 - auc: 0.9332 - val_loss: 0.1013 - val_binary_accuracy: 0.9848 - val_f1_score: 0.8726 - val_hamming_loss: 0.0152 - val_recall: 0.9611 - val_precision: 0.9386 - val_auc: 0.9178\n",
            "Epoch 71/200\n",
            "278/278 [==============================] - 26s 93ms/step - loss: 0.0097 - binary_accuracy: 0.9975 - f1_score: 0.9260 - hamming_loss: 0.0025 - recall: 0.9973 - precision: 0.9842 - auc: 0.9332 - val_loss: 0.0973 - val_binary_accuracy: 0.9852 - val_f1_score: 0.8718 - val_hamming_loss: 0.0148 - val_recall: 0.9611 - val_precision: 0.9407 - val_auc: 0.9215\n",
            "Epoch 72/200\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-1d0d2f33d013>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     batch_size=512)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 _r=1):\n\u001b[1;32m   1215\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1216\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1217\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 910\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    940\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 942\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3129\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3130\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3131\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3133\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1958\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1959\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1960\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1961\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1962\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    601\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 603\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    604\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    605\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 59\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     60\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}